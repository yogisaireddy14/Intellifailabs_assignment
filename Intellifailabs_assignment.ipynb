{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkCEl0Rkmpfm6Q13YGE01x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogisaireddy14/Intellifailabs_assignment/blob/main/Intellifailabs_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn16IlSifCdS"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/KwaiVGI/LivePortrait.git\n",
        "%cd LivePortrait"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "UmdapVuxfMH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.41.0\n",
        "!pip install numpy==1.24.4 onnxruntime-gpu==1.17.1"
      ],
      "metadata": {
        "id": "bFHkwX0gfmS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"PyTorch CUDA available? \", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current device:\", torch.cuda.get_device_name(0))\n",
        "    print(\"CUDA capability:\", torch.version.cuda)\n",
        "else:\n",
        "    print(\"No GPU detected.\")"
      ],
      "metadata": {
        "id": "PS3sB_yEge3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download KwaiVGI/LivePortrait \\\n",
        "  --local-dir pretrained_weights \\\n",
        "  --exclude \"*.git*\" \"README.md\" \"docs\""
      ],
      "metadata": {
        "id": "3kEk43yoggyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "_ = torch.zeros((1,1), device=\"cuda\")\n",
        "torch.cuda.synchronize()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Vhj0lmANgpaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=memory.used --format=csv,nounits,noheader"
      ],
      "metadata": {
        "id": "H0pCFIwugs9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import subprocess\n",
        "import sys\n",
        "SRC_IMG = \"/content/LivePortrait/assets/examples/source/s9.jpg\"\n",
        "DRIVE_VID = \"/content/LivePortrait/assets/examples/driving/d0.mp4\"\n",
        "OUT_DIR = \"animations\"\n",
        "\n",
        "start_time = time.time()\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [\n",
        "            sys.executable, \"/content/LivePortrait/inference.py\",\n",
        "            \"-s\", SRC_IMG,\n",
        "            \"-d\", DRIVE_VID,\n",
        "            \"-o\", OUT_DIR\n",
        "        ],\n",
        "        check=True,\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\" inference.py exited with a non-zero status.\")\n",
        "    print(\"------ stdout ------\")\n",
        "    print(e.stdout)\n",
        "    print(\"------ stderr ------\")\n",
        "    print(e.stderr)\n",
        "    raise\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_ms = (end_time - start_time) * 1000\n",
        "print(f\"=== Elapsed inference time (FP32): {elapsed_ms:.0f} ms total ===\")\n"
      ],
      "metadata": {
        "id": "zU-cF_cVgvpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from src.modules.spade_generator import SPADEDecoder\n",
        "\n",
        "generator = SPADEDecoder()\n",
        "generator.eval().cuda()\n",
        "\n",
        "ckpt_path = \"/content/LivePortrait/pretrained_weights/liveportrait/base_models/spade_generator.pth\"\n",
        "state_dict = torch.load(ckpt_path, map_location=\"cuda\")\n",
        "\n",
        "generator.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "dummy_input = torch.randn(512, 256, 3, 3).cuda()\n",
        "with torch.cuda.amp.autocast(), torch.no_grad():\n",
        "    output = generator(dummy_input)\n",
        "\n",
        "print(\" Inference complete. Output shape:\", output.shape)\n",
        "\n",
        "traced = torch.jit.trace(generator, dummy_input)\n",
        "torchscript_path = \"/content/spade_generator_torchscript.pt\"\n",
        "traced.save(torchscript_path)\n",
        "print(f\" TorchScript model saved at: {torchscript_path}\")"
      ],
      "metadata": {
        "id": "8Jm0uDvKgyGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    _ = generator(dummy_input)\n",
        "\n",
        "# Time it\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = generator(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Original Model Avg Inference Time: {(end - start)/100:.6f} sec\")\n",
        "optimized_model = torch.jit.load(\"/content/spade_generator_torchscript.pt\").eval().cuda()\n",
        "\n",
        "# Warm-up\n",
        "for _ in range(10):\n",
        "    _ = optimized_model(dummy_input)\n",
        "\n",
        "# Time it\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = optimized_model(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"TorchScript Model Avg Inference Time: {(end - start)/100:.6f} sec\")"
      ],
      "metadata": {
        "id": "QQ8lMjTNhAP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from src.modules.motion_extractor import MotionExtractor\n",
        "\n",
        "generator = MotionExtractor(num_kp=21)\n",
        "generator.eval().cuda()\n",
        "\n",
        "ckpt_path = \"/content/LivePortrait/pretrained_weights/liveportrait/base_models/motion_extractor.pth\"\n",
        "state_dict = torch.load(ckpt_path, map_location=\"cuda\")\n",
        "generator.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "dummy_input = torch.randn(1,3,256,256).cuda()\n",
        "\n",
        "with torch.cuda.amp.autocast(), torch.no_grad():\n",
        "    output = dict(generator(dummy_input))\n",
        "\n",
        "print(\" Inference complete. Output shape:\", output)\n",
        "\n",
        "\n",
        "traced = torch.jit.trace(generator, dummy_input, strict=False)\n",
        "torchscript_path = \"/content/motion_extractor_torchscript.pt\"\n",
        "traced.save(torchscript_path)\n",
        "print(f\" TorchScript model saved at: {torchscript_path}\")\n"
      ],
      "metadata": {
        "id": "y8jqQHh9hD3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    _ = generator(dummy_input)\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = generator(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Original Model Avg Inference Time: {(end - start)/100:.6f} sec\")\n",
        "optimized_model = torch.jit.load(\"/content/motion_extractor_torchscript.pt\").eval().cuda()\n",
        "\n",
        "\n",
        "for _ in range(10):\n",
        "    _ = optimized_model(dummy_input)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = optimized_model(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"TorchScript Model Avg Inference Time: {(end - start)/100:.6f} sec\")"
      ],
      "metadata": {
        "id": "oJ4TqY8khHtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from src.modules.appearance_feature_extractor import AppearanceFeatureExtractor\n",
        "\n",
        "\n",
        "model = AppearanceFeatureExtractor(\n",
        "    image_channel=3,\n",
        "    block_expansion=64,\n",
        "    num_down_blocks=2,\n",
        "    max_features=512,\n",
        "    reshape_channel=32,\n",
        "    reshape_depth=16,\n",
        "    num_resblocks=6\n",
        ")\n",
        "model.eval().cuda()\n",
        "\n",
        "\n",
        "ckpt_path = \"/content/LivePortrait/pretrained_weights/liveportrait/base_models/appearance_feature_extractor.pth\"\n",
        "state_dict = torch.load(ckpt_path, map_location=\"cuda\")\n",
        "model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 256, 256).cuda()\n",
        "\n",
        "\n",
        "traced = torch.jit.trace(model, dummy_input, strict=False)\n",
        "\n",
        "\n",
        "torchscript_path = \"/content/appearance_feature_extractor.pt\"\n",
        "traced.save(torchscript_path)\n",
        "\n",
        "print(f\" TorchScript model saved at: {torchscript_path}\")\n"
      ],
      "metadata": {
        "id": "hNqvtkgchZLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    _ = generator(dummy_input)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = generator(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Original Model Avg Inference Time: {(end - start)/100:.6f} sec\")\n",
        "optimized_model = torch.jit.load(\"/content/appearance_feature_extractor.pt\").eval().cuda()\n",
        "\n",
        "\n",
        "for _ in range(10):\n",
        "    _ = optimized_model(dummy_input)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = optimized_model(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"TorchScript Model Avg Inference Time: {(end - start)/100:.6f} sec\")"
      ],
      "metadata": {
        "id": "LS0ckEHehdbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from src.modules.stitching_retargeting_network import StitchingRetargetingNetwork\n",
        "\n",
        "\n",
        "generator = StitchingRetargetingNetwork( input_size=256,\n",
        "    hidden_sizes=[512, 512, 256],\n",
        "    output_size=3)\n",
        "generator.eval().cuda()\n",
        "\n",
        "\n",
        "ckpt_path = \"/content/LivePortrait/pretrained_weights/liveportrait/retargeting_models/stitching_retargeting_module.pth\"\n",
        "state_dict = torch.load(ckpt_path, map_location=\"cuda\")\n",
        "for name, param in generator.named_parameters():\n",
        "    print(name, param.shape)\n",
        "\n",
        "generator.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(1, 256).cuda()\n",
        "with torch.cuda.amp.autocast(), torch.no_grad():\n",
        "    output = generator(dummy_input)\n",
        "\n",
        "print(\" Inference complete. Output shape:\", output.shape)\n",
        "\n",
        "\n",
        "traced = torch.jit.trace(generator, dummy_input)\n",
        "torchscript_path = \"/content/stitching_retargeting_torchscript.pt\"\n",
        "traced.save(torchscript_path)\n",
        "print(f\" TorchScript model saved at: {torchscript_path}\")"
      ],
      "metadata": {
        "id": "f5kG_v8QhemQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from src.modules.stitching_retargeting_network import StitchingRetargetingNetwork\n",
        "\n",
        "\n",
        "generator = StitchingRetargetingNetwork( input_size=256,\n",
        "    hidden_sizes=[512, 512, 256],\n",
        "    output_size=3)\n",
        "ckpt_path = \"/content/LivePortrait/pretrained_weights/liveportrait/retargeting_models/stitching_retargeting_module.pth\"\n",
        "state_dict = torch.load(ckpt_path, map_location=\"cuda\")\n",
        "generator.load_state_dict(state_dict, strict=False)\n",
        "generator.eval().cuda()\n",
        "dummy_input = torch.randn(1, 256).cuda()\n",
        "for _ in range(10):\n",
        "    _ = generator(dummy_input)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = generator(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Original Model Avg Inference Time: {(end - start)/100:.6f} sec\")\n",
        "optimized_model = torch.jit.load(\"/content/stitching_retargeting_torchscript.pt\").eval().cuda()\n",
        "\n",
        "\n",
        "for _ in range(10):\n",
        "    _ = optimized_model(dummy_input)\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = optimized_model(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"TorchScript Model Avg Inference Time: {(end - start)/100:.6f} sec\")"
      ],
      "metadata": {
        "id": "ihNchqKMhgvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import torch\n",
        "from src.config.inference_config import InferenceConfig\n",
        "from src.config.crop_config import CropConfig\n",
        "from src.live_portrait_pipeline import LivePortraitPipeline\n",
        "from IPython.display import Video, display\n",
        "from src.config.argument_config import ArgumentConfig\n",
        "\n",
        "SRC_IMG = \"/content/LivePortrait/assets/examples/source/s9.jpg\"\n",
        "DRIVE_VID = \"/content/LivePortrait/assets/examples/driving/d0.mp4\"\n",
        "OUT_DIR = \"animations\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "parsed_args = ArgumentConfig(source=SRC_IMG, driving=DRIVE_VID, output_dir=OUT_DIR)\n",
        "\n",
        "pipeline = LivePortraitPipeline(inference_cfg=InferenceConfig(), crop_cfg=CropConfig())\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.cuda.amp.autocast(), torch.no_grad():\n",
        "    animation = pipeline.execute(parsed_args)\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_ms = (end_time - start_time) * 1000\n",
        "print(f\"=== Elapsed inference time (AMP only): {elapsed_ms:.0f} ms total ===\")\n"
      ],
      "metadata": {
        "id": "tbYpIKVVhjj1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}